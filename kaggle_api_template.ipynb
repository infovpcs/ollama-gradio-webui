{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama Gradio WebUI with vLLM - API Server Setup\n",
    "\n",
    "This notebook demonstrates how to run the Ollama Gradio WebUI as an API server using ngrok in Kaggle.\n",
    "\n",
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/infovpcs/ollama-gradio-webui.git\n",
    "%cd ollama-gradio-webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!sh install_deps.sh\n",
    "\n",
    "# Install ngrok\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start the API Server with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from pyngrok import ngrok, conf\n",
    "import os\n",
    "\n",
    "# Set environment variables for Kaggle\n",
    "os.environ[\"GRADIO_SERVER_NAME\"] = \"0.0.0.0\"\n",
    "os.environ[\"GRADIO_SERVER_PORT\"] = \"7860\"\n",
    "os.environ[\"OLLAMA_USE_VLLM\"] = \"true\"\n",
    "os.environ[\"KAGGLE_API_MODE\"] = \"true\"\n",
    "\n",
    "# Optional: Set your ngrok authtoken if you have one\n",
    "# conf.get_default().auth_token = \"your_ngrok_authtoken\"\n",
    "\n",
    "# Create ngrok tunnel\n",
    "ngrok_tunnel = ngrok.connect(addr=\"localhost:7860\")\n",
    "print(f\"\\nðŸ”— API Server is accessible at: {ngrok_tunnel.public_url}\")\n",
    "print(f\"\\nâœ… API Endpoints:\")\n",
    "print(f\"   - Chat API: {ngrok_tunnel.public_url}/api/chat\")\n",
    "print(f\"   - React Agent API: {ngrok_tunnel.public_url}/api/react_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Start the Ollama server and the vLLM app in the background\n",
    "!sh start_vllm.sh &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using the API Endpoints\n",
    "\n",
    "Now you can use the API endpoints to interact with the Ollama models. Here are examples using `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your actual ngrok URL\n",
    "API_BASE_URL = ngrok_tunnel.public_url\n",
    "\n",
    "# Example: Using the Chat API\n",
    "def chat_with_ollama(message, model=\"qwen3:vpcs-vllm\", enable_context=True):\n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/api/chat\",\n",
    "        json={\n",
    "            \"message\": message,\n",
    "            \"model\": model,\n",
    "            \"enable_context\": enable_context\n",
    "        }\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "# Example: Using the React Agent API\n",
    "def react_agent_query(query, odoo_version=\"18.0\", model=\"qwen3:vpcs-vllm\"):\n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/api/react_agent\",\n",
    "        json={\n",
    "            \"query\": query,\n",
    "            \"odoo_version\": odoo_version,\n",
    "            \"model\": model\n",
    "        }\n",
    "    )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test the Chat API\n",
    "response = chat_with_ollama(\"Tell me about Odoo 18 features\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test the React Agent API\n",
    "response = react_agent_query(\"Create a simple Odoo module for task management\")\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integration with External Applications\n",
    "\n",
    "You can now use the ngrok URL to integrate with external applications such as:\n",
    "- Mobile apps\n",
    "- Web applications\n",
    "- Other notebooks or scripts\n",
    "- Automation tools\n",
    "\n",
    "The API will remain accessible as long as this notebook is running (up to 72 hours in Kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Keep the notebook running\n",
    "import time\n",
    "while True:\n",
    "    print(\"API server is running... Press Ctrl+C to stop\")\n",
    "    time.sleep(600)  # Check every 10 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
