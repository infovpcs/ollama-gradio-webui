#!/bin/sh
# Script to install dependencies for Ollama Gradio WebUI with vLLM
# Compatible with local environments and Kaggle notebooks

echo "ğŸš€ Installing dependencies for Ollama Gradio WebUI with vLLM"

# Detect environment
IS_KAGGLE=false
if [ -d "/kaggle" ]; then
    IS_KAGGLE=true
    echo "ğŸ“Š Detected Kaggle notebook environment"
elif [ "$(uname)" = "Darwin" ]; then
    IS_MAC=true
    echo "ğŸ“± Detected macOS environment"
else
    IS_LINUX=true
    echo "ğŸ–¥ï¸ Detected Linux/Windows environment"
fi

# Skip virtual environment creation on Kaggle
if [ "$IS_KAGGLE" = false ] && [ -z "${VIRTUAL_ENV}" ]; then
    echo "ğŸ”§ Creating virtual environment..."
    python3 -m venv .venv
    . .venv/bin/activate
fi

# Install basic dependencies first
echo "ğŸ“¦ Installing basic dependencies..."
pip install -q gradio==3.50.2 ollama==0.1.6 pydantic==1.10.8 requests markdown numpy

# Install PyTorch based on environment
if [ "$IS_KAGGLE" = true ]; then
    echo "âœ… Using pre-installed PyTorch in Kaggle environment"
else
    echo "ğŸ”¥ Installing PyTorch (required before vLLM)..."
    if [ "$IS_MAC" = true ]; then
        pip install -q torch torchvision torchaudio
    else
        pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    fi
fi

# Install Hugging Face libraries
echo "ğŸ¤— Installing Hugging Face libraries..."
pip install -q transformers>=4.33.0 accelerate>=0.23.0

# Install vLLM and related dependencies based on environment
if [ "$IS_KAGGLE" = true ]; then
    echo "ğŸ“¦ Installing Kaggle-specific dependencies..."
    
    # Install additional dependencies that might be needed
    pip install -q einops>=0.6.1 sentencepiece bitsandbytes
    
    # Install xformers for better performance if not already installed
    if ! python -c "import xformers" 2>/dev/null; then
        echo "ğŸ“¦ Installing xformers in Kaggle environment..."
        pip install -q xformers
    fi
    
    # Check if vLLM is already installed in Kaggle
    if python -c "import vllm" 2>/dev/null; then
        echo "âœ… vLLM is already installed in Kaggle environment"
    else
        echo "ğŸ“¦ Installing vLLM in Kaggle environment..."
        pip install -q vllm
    fi
    
    echo "âœ… Kaggle setup complete! Both notebook and server modes are supported."
elif [ "$IS_MAC" = true ]; then
    echo "ğŸ“¦ Installing macOS compatible dependencies..."
    
    # Mac users should use Ollama's built-in optimizations instead of vLLM
    # But we can install minimal components for compatibility
    pip install -q einops>=0.6.1 sentencepiece ray
    
    echo "âš ï¸ Note: vLLM with GPU acceleration is not fully supported on macOS."
    echo "âš ï¸ Using Ollama's built-in optimizations instead."
else
    echo "ğŸ“¦ Installing vLLM and related dependencies for Linux/Windows..."
    
    # Install prerequisites
    pip install -q einops>=0.6.1 sentencepiece ray
    
    # First install xformers separately to avoid build issues
    pip install -q xformers bitsandbytes
    
    # Then install vLLM
    pip install -q vllm>=0.2.0
    
    echo "âœ… vLLM installed with GPU support"
fi

echo "âœ… All dependencies installed successfully!"
echo "ğŸ“ Note: For Kaggle integration, ensure 'Internet' is enabled in the notebook settings."
echo "ğŸ”§ Run ./start_vllm.sh to start the application with vLLM optimizations."

